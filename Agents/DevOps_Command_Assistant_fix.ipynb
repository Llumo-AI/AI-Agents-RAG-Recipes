{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d77ca4f",
   "metadata": {
    "id": "1d77ca4f"
   },
   "source": [
    "# ğŸš€ **DevOps Command Line Assistant using `agno` and OpenAI**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Welcome! This notebook walks you through building a DevOps Assistant that interprets natural language commands to manage infrastructure tasks like Kubernetes, CI/CD, Linux services, and Terraformâ€”all routed through intelligent agents.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d43190",
   "metadata": {
    "id": "a5d43190"
   },
   "source": [
    "## ğŸ“¦ **1. Install Dependencies**\n",
    "We start by installing the `agno` framework, which enables multi-agent workflows with AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d68c20d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d68c20d5",
    "outputId": "520d2e61-71c5-4236-ec8a-33c9ed8001fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m616.6/616.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install agno -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97131b7",
   "metadata": {
    "id": "d97131b7"
   },
   "source": [
    "## ğŸ” **2. Set Up Environment Variables**\n",
    "To use OpenAI's models, you need to provide your API key. For security, set it via an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c41f4f3",
   "metadata": {
    "id": "8c41f4f3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'Enter your open ai key here.'  # Replace with your actual key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acade0b",
   "metadata": {
    "id": "8acade0b"
   },
   "source": [
    "## ğŸ§  **3. Import Required Libraries**\n",
    "Let's import the core components needed to define agents and teams using `agno`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00bb524",
   "metadata": {
    "id": "e00bb524"
   },
   "outputs": [],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.team.team import Team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968ba3f8",
   "metadata": {
    "id": "968ba3f8"
   },
   "source": [
    "## ğŸ› ï¸ **4. Define Individual DevOps Agents**\n",
    "Each agent specializes in a particular area: Linux operations, Kubernetes, Terraform, or CI/CD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fe5ab8c",
   "metadata": {
    "id": "9fe5ab8c"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ğŸ§ LinuxOps Agent\n",
    "# Handles common Linux command-line operations such as restarting services, checking logs, and system diagnostics.\n",
    "linux_agent = Agent(\n",
    "    name='LinuxOps Agent',\n",
    "    role='Handles Linux command line tasks such as restarting services and checking logs.',\n",
    "    model=OpenAIChat(id='gpt-4o'),\n",
    ")\n",
    "\n",
    "# â˜¸ï¸ Kubernetes Agent\n",
    "# Specializes in managing Kubernetes clusters via kubectl â€” including inspecting pod status and managing deployments.\n",
    "k8s_agent = Agent(\n",
    "    name='Kubernetes Agent',\n",
    "    role='Manages Kubernetes clusters using kubectl for tasks like checking pod statuses and managing deployments.',\n",
    "    model=OpenAIChat(id='gpt-4o'),\n",
    ")\n",
    "\n",
    "# âš™ï¸ Terraform Agent\n",
    "# Executes infrastructure-as-code operations using Terraform â€” applies, plans, state management, and validation.\n",
    "terraform_agent = Agent(\n",
    "    name='Terraform Agent',\n",
    "    role='Manages infrastructure using Terraform commands.',\n",
    "    model=OpenAIChat(id='gpt-4o'),\n",
    ")\n",
    "\n",
    "# ğŸ”„ CI/CD Agent\n",
    "# Handles automation around continuous integration and deployment â€” like triggering builds and checking pipeline status.\n",
    "cicd_agent = Agent(\n",
    "    name='CI/CD Agent',\n",
    "    role='Handles CI/CD tasks such as triggering builds and checking pipeline statuses.',\n",
    "    model=OpenAIChat(id='gpt-4o'),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08ea3d",
   "metadata": {
    "id": "4c08ea3d"
   },
   "source": [
    "## ğŸ‘¥ **5. Build the DevOps Team**\n",
    "The team acts as a router. Based on the type of task, it dispatches to the right agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0635bc17",
   "metadata": {
    "id": "0635bc17"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This team intelligently routes infrastructure-related tasks to the right domain-specific agent (Linux, Kubernetes, Terraform, CI/CD).\n",
    "devops_team = Team(\n",
    "    name='DevOps Command Assistant',\n",
    "\n",
    "    # ğŸ§­ Routing mode: Automatically selects the most appropriate agent based on task context.\n",
    "    mode='route',\n",
    "\n",
    "    # ğŸ”§ Default model for routing logic\n",
    "    model=OpenAIChat(id='gpt-4o'),\n",
    "\n",
    "    # ğŸ‘¥ Members: Specialized agents for different DevOps domains\n",
    "    members=[linux_agent, k8s_agent, terraform_agent, cicd_agent],\n",
    "\n",
    "    # ğŸ’¬ Whether to show tool call traces in the output\n",
    "    show_tool_calls=False,\n",
    "\n",
    "    # ğŸ“ Enable Markdown formatting in responses\n",
    "    markdown=True,\n",
    "\n",
    "    # ğŸ“˜ Description of the team's purpose\n",
    "    description='Routes infrastructure tasks to the appropriate specialist agent.',\n",
    "\n",
    "    # ğŸ“œ Routing instructions to guide how the assistant delegates tasks\n",
    "    instructions=[\n",
    "        'Determine the nature of the task: Linux, Kubernetes, Terraform, or CI/CD.',\n",
    "        'Route the task to the appropriate agent.',\n",
    "        'If the task is ambiguous, ask the user for clarification.'\n",
    "    ],\n",
    "\n",
    "    # ğŸ‘€ Hides individual agent responses unless needed for debugging\n",
    "    show_members_responses=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b19ac56",
   "metadata": {
    "id": "6b19ac56"
   },
   "source": [
    "## ğŸ§ª **6. Try Sample Prompts**\n",
    "Now let's see the assistant in action with a few natural language commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50e5bf46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234,
     "referenced_widgets": [
      "d8c25d99884a4246807bddb45626bbd0",
      "2d535404aa354ca290d782809d61e981"
     ]
    },
    "id": "50e5bf46",
    "outputId": "79110fae-c696-42aa-d883-3bbe4e446b78"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c25d99884a4246807bddb45626bbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Restart a Linux service\n",
    "devops_team.print_response('Restart the nginx service on production-server',stream = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "OncSySSWMqcw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669,
     "referenced_widgets": [
      "671b3015757949d396ca95ffe99ddc87",
      "f11f84db42234d66b7f2a485738a6c76"
     ]
    },
    "id": "OncSySSWMqcw",
    "outputId": "f967e02a-c238-4cb2-9c11-3b59bc9b40f2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671b3015757949d396ca95ffe99ddc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check Kubernetes pods\n",
    "devops_team.print_response('Get all pods in kube-system namespace',stream = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ZEUdzoN1Mqu5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887,
     "referenced_widgets": [
      "ef6e138783f54b8c9d78e49d50c32a78",
      "b63de688dfe1434b834f63243cb367a1"
     ]
    },
    "id": "ZEUdzoN1Mqu5",
    "outputId": "12e6e73a-a4e9-4dba-f437-33beed0ad63e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6e138783f54b8c9d78e49d50c32a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply Terraform plan\n",
    "devops_team.print_response('print_response terraform apply on the staging environment',stream = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "qDwEoRddMq54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452,
     "referenced_widgets": [
      "53943e27573d420687167aa468531d43",
      "17993d765c0e4259b9a7dfaaeb6b04af"
     ]
    },
    "id": "qDwEoRddMq54",
    "outputId": "87fd2f14-5895-4b2c-d8b5-50abeb23d42f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53943e27573d420687167aa468531d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trigger CI/CD pipeline\n",
    "devops_team.print_response('Trigger the nightly Jenkins build',stream = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IIFcz6J7MrDY",
   "metadata": {
    "id": "IIFcz6J7MrDY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da1ca083",
   "metadata": {
    "id": "da1ca083"
   },
   "source": [
    "## **ğŸŒ Bonus: Swappable Models**\n",
    "You can swap `OpenAIChat` with `Gemini`, `DeepSeek`, or others by just changing the model class while keeping the logic intact."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
