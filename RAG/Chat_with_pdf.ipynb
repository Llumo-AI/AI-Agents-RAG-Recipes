{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üéØ RAG Pipeline from PDFs with Images & Tables using LangChain, Unstructured & OpenAI\n",
        "\n",
        "## üìò Overview\n",
        "This notebook demonstrates how to build a Retrieval-Augmented Generation (RAG) system that can parse PDFs (including images and tables), embed the content, and answer natural language queries using LangChain and OpenAI.\n",
        "\n",
        "## üîç What this notebook does:\n",
        "- Extracts structured and unstructured content from PDFs using `unstructured`.\n",
        "- Parses tables, images, and text with high-resolution mode.\n",
        "- Embeds parsed chunks using `OpenAIEmbeddings`.\n",
        "- Stores and retrieves documents using `FAISS` vectorstore.\n",
        "- Answers questions contextually using `ChatOpenAI` and LangChain RAG chain.\n",
        "\n",
        "## üí° Example Query\n",
        "\"Compare Artificial Intelligence and Machine Learning from the document.\"\n"
      ],
      "metadata": {
        "id": "XL-pLbzmGB47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚öôÔ∏è Setup\n",
        "üîß Install dependencies"
      ],
      "metadata": {
        "id": "364nrgEOGFY7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9-2KmBxF4_s"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet faiss-cpu pytesseract unstructured-client \"unstructured[all-docs]\"\n",
        "!pip install langchain_openai langchain-community\n",
        "!apt-get install -y poppler-utils tesseract-ocr libtesseract-dev\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üîë Set up API key"
      ],
      "metadata": {
        "id": "DZ83XtscGIAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Enter Your OPENAI_API_KEY\"\n",
        "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY') # Uncomment if you Stored your key securely in Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "6cwE-_ADGIa9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìÑ Step 1: Parse PDF with Unstructured"
      ],
      "metadata": {
        "id": "-RzPLqt-GRiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured.partition.pdf import partition_pdf\n",
        "\n",
        "filename = \"/content/Ml_sample.pdf\" # Path to your PDF file\n",
        "\n",
        "# Extract elements including images, tables, and structured text\n",
        "pdf_elements = partition_pdf(\n",
        "    filename=filename,\n",
        "    extract_images_in_pdf=True,               # Enable image extraction\n",
        "    strategy=\"hi_res\",                       # Use high-resolution parsing\n",
        "    hi_res_model_name=\"yolox\",               # YOLOX model for detecting layout\n",
        "    infer_table_structure=True,               # Try to parse tables\n",
        "    chunking_strategy=\"by_title\",            # Split text by document headings\n",
        "    max_characters=3000,\n",
        "    combine_text_under_n_chars=200\n",
        ")\n"
      ],
      "metadata": {
        "id": "rpNx_IPIGJWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîç Inspect parsed elements\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vkBpV_bMGUW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze the types of elements extracted\n",
        "from collections import Counter\n",
        "category_counts = Counter(str(type(element)) for element in pdf_elements)\n",
        "category_counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VMZhHmKGUpw",
        "outputId": "86e93505-9df7-4414-e262-4ce797f99bec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({\"<class 'unstructured.documents.elements.CompositeElement'>\": 47})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üìö Step 2: Create LangChain Documents"
      ],
      "metadata": {
        "id": "I3R9f-B2Gqne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert each element into a searchable Document\n",
        "from langchain.schema import Document\n",
        "documents = [Document(page_content=el.text, metadata={\"source\": filename}) for el in pdf_elements]\n"
      ],
      "metadata": {
        "id": "jGybXP1hGcAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† Step 3: Embed with OpenAI + FAISS"
      ],
      "metadata": {
        "id": "WDigkb6NGtfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "#Build FAISS Vector Store from the documents\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "#Set up a retriever from the vectorstore\n",
        "retriever = vectorstore.as_retriever()\n"
      ],
      "metadata": {
        "id": "OtOV83mtGtyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß© Step 4: Setup LangChain RAG Chain"
      ],
      "metadata": {
        "id": "ZeivnOdvGvm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the RAG pipeline using LangChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "\n",
        "# Define how the question and context are formatted to the model\n",
        "template = \"\"\"\n",
        "You are a helpful assistant that answers questions based on the provided context, which can include text and tables.\n",
        "Use the provided context to answer the question.\n",
        "Question: {input}\n",
        "Context: {context}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# Chain: Retrieve context ‚Üí Fill prompt ‚Üí Run LLM ‚Üí Return response\n",
        "rag_chain = (\n",
        "    {\"context\": retriever,  \"input\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n"
      ],
      "metadata": {
        "id": "nYT_H4x2Gwkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùì Run a Query"
      ],
      "metadata": {
        "id": "ySbLLdp8Gzsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask a question to the RAG pipeline\n",
        "response1 = rag_chain.invoke(\"Compare Artificial Intelligence and Machine Learning from the document.\")\n",
        "print(response1)\n",
        "response2 = rag_chain.invoke(\"what is machine learing \")\n",
        "print(response2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRn9JeV1G0Pt",
        "outputId": "e83d8689-22d7-46a3-b3af-383470c7e7b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Artificial Intelligence (AI) can be defined as the branch of computer science that aims to create intelligent machines capable of behaving like humans, thinking like humans, and making decisions. AI involves machines having human-based skills such as learning, reasoning, and problem-solving. \n",
            "\n",
            "On the other hand, Machine Learning is a growing technology that enables computers to learn automatically from past data. It uses various algorithms to build mathematical models and make predictions based on historical data or information. Machine Learning is currently being utilized for tasks such as image recognition, speech recognition, email filtering, and recommender systems.\n",
            "\n",
            "Deep Learning is a subset of AI and Machine Learning that is based on neural networks imitating the human brain. It involves nonlinear processing units for feature extraction and transformation. Deep learning is implemented using Neural Networks, inspired by the biological neurons in the brain. This technique allows for learning feature hierarchies based on artificial neural networks.\n",
            "Machine learning is a technology that enables machines to learn automatically from past data, improve performance based on experiences, and make predictions without being explicitly programmed. It involves the use of various algorithms to build mathematical models and make predictions using historical data or information. Machine learning is being utilized in tasks such as image recognition, speech recognition, email filtering, social media auto-tagging, recommender systems, and more.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the output with Llumo Ai\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-1fq3VzNHDB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to Evaluate the output\n",
        "User_Query=\"Compare Artificial Intelligence\"\n",
        "llm_response=response1\n",
        "inputs = {}\n",
        "import requests\n",
        "# Define the endpoint, headers, and payload\n",
        "LLUMO_ENDPOINT = \"https://app.llumo.ai/api/create-eval-analytics\"\n",
        "headers = {\n",
        "    \"Authorization\": \"Bearer {Your llumo api key}\", # Replace with your LLumo API key it will look like this \"Bearer A1B2C3\"\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "payload = {\n",
        "    \"prompt\": User_Query,\n",
        "    \"input\": inputs,\n",
        "    \"output\": llm_response,\n",
        "    \"analytics\": [\"Context Utilization\"] # ANALYTICS NAME are Confidence,Clarity,Context.....etc.\n",
        "}\n",
        "# Make the API request\n",
        "response = requests.post(LLUMO_ENDPOINT, json=payload, headers=headers)\n",
        "try:\n",
        "    result = response.json()  # Parse the JSON response\n",
        "    print(\"statusCode : \", result['data']['statusCode'])\n",
        "    print(\"message : \",result['data']['message'])\n",
        "    # Extract the 'data' part\n",
        "    data = result.get('data', {})\n",
        "    print(\"Analytics:\", data)\n",
        "    # Return the data and a success flag\n",
        "\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_mUpHabG-W1",
        "outputId": "49445788-56ed-486d-e29d-0dec5df50848"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "statusCode :  200\n",
            "message :  SUCCESS\n",
            "Analytics: {'data': '{\"analyticsScore\": {\"*the output should correctly define ai and ml and compare them.\": 75, \"*the output should provide a clear and concise comparison of ai and ml, highlighting their key differences and similarities.\": 70, \"*the output should be well-structured, easy to understand, and free of grammatical errors.\": 85, \"*the output should accurately reflect the information present in the provided document (although no document was provided in this example).\": 0, \"overallScore\": 58}, \"reasoning\": {\"*the output should correctly define ai and ml and compare them.\": [\"The output correctly defines AI as a branch of computer science aiming to create intelligent machines.\", \"It accurately describes ML as enabling computers to learn from data using algorithms.\", \"The comparison is present but could be more explicit.  While it contrasts the approaches, a more direct comparative analysis of their capabilities, limitations, or applications would improve the score.\", \"The definitions are clear and concise, but lack depth in exploring the nuances of each field.\"], \"*the output should provide a clear and concise comparison of ai and ml, highlighting their key differences and similarities.\": [\"The output presents separate definitions of AI and ML, which is a good start.\", \"It implicitly highlights a key difference: AI's broader goal of human-like intelligence versus ML's focus on learning from data.\", \"However, a more structured comparison, using phrases like 'In contrast to...', 'While both...','However...' would strengthen the response.\", \"The output lacks explicit discussion of similarities, such as both relying on algorithms or being used for similar tasks (though some overlap is implied).\"], \"*the output should be well-structured, easy to understand, and free of grammatical errors.\": [\"The output is well-structured with clear paragraphs separating the definitions of AI and ML.\", \"The language is easy to understand, using simple and precise terms.\", \"The grammar is correct and the writing style is clear and concise.\", \"There are no significant grammatical errors or stylistic issues.\"], \"*the output should accurately reflect the information present in the provided document (although no document was provided in this example).\": [\"No document was provided, making it impossible to assess whether the output reflects its content.\", \"The response is evaluated based on general knowledge of AI and ML, not on a specific document.\"], \"overallScore\": \"Calculated based on individual metric scores\"}, \"inputTokenCount\": 10, \"outputTokenCount\": 117, \"totalToken\": 127, \"cost\": 0.0007620000000000001, \"isRepeat\": false, \"isError\": true, \"isRefusal\": true}', 'statusCode': 200, 'message': 'SUCCESS'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UFuST1ftIUFY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}