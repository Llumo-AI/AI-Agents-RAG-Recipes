{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3b2a3cbc",
      "metadata": {
        "id": "3b2a3cbc"
      },
      "source": [
        "# üìä **Strategy Report Builder ‚Äì Sales Transcript to Insightful Report**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This notebook uses Google Gemini (`genai`) to analyze sales conversations and extract a structured strategy report including client needs, proposed solutions, objections, next steps, and strategic insights.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca27a021",
      "metadata": {
        "id": "ca27a021"
      },
      "source": [
        "## üß© **1. Install Required Libraries**\n",
        "Ensure the required Google GenAI Python SDK is installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "91f41fcc",
      "metadata": {
        "id": "91f41fcc"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7240977",
      "metadata": {
        "id": "e7240977"
      },
      "source": [
        "## üîê **2. Configure API Key**\n",
        "Set your Google API key (keep it secret!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2893fe28",
      "metadata": {
        "id": "2893fe28"
      },
      "outputs": [],
      "source": [
        "# Replace the empty string with your actual API key. This key is used for authentication with the Google Generative AI..\n",
        "import os\n",
        "os.environ['GEMINI_API_KEY'] = \"your-actual-api-key-here\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7e61e38",
      "metadata": {
        "id": "d7e61e38"
      },
      "source": [
        "## üì•**3. Import Libraries**\n",
        "We‚Äôll import all nec`essary modules from the Google GenAI SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1d40547d",
      "metadata": {
        "id": "1d40547d"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8140100",
      "metadata": {
        "id": "c8140100"
      },
      "source": [
        "## üß† **4. Define the Strategy Report Agent**\n",
        "This function analyzes the transcript and generates a structured report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8b522681",
      "metadata": {
        "id": "8b522681"
      },
      "outputs": [],
      "source": [
        "# üß† Sales Report Agent\n",
        "# This function analyzes a sales transcript and generates a structured strategy report using Google Gemini\n",
        "\n",
        "def sales_report(transcript):\n",
        "    # Step 1: Define the system-level instruction for the model\n",
        "    # This sets the persona of the model as a business analyst focusing on extracting insights from sales conversations\n",
        "    strategy_system_prompt = \"\"\"\n",
        "    You are a strategic business analyst specializing in interpreting sales conversations.\n",
        "    Your role is to extract actionable insights, structure them into a report, and ensure clarity,\n",
        "    completeness, and business relevance. Focus on summarizing client needs, solutions offered,\n",
        "    objections, next steps, and strategic takeaways.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 2: Define the dynamic user prompt with placeholders for the transcript\n",
        "    # This gives explicit instructions to the model on what kind of output is expected\n",
        "    user_prompt = \"\"\"\n",
        "    You are a Strategy Report Builder.\n",
        "\n",
        "    Your job is to analyze a sales conversation transcript between a salesperson and a client,\n",
        "    and generate a clear, actionable, and structured strategy report based on the discussion.\n",
        "\n",
        "    Your report should include the following sections:\n",
        "    1. **Client Needs & Pain Points**\n",
        "    2. **Proposed Solutions**\n",
        "    3. **Objections or Concerns Raised**\n",
        "    4. **Next Steps & Follow-ups**\n",
        "    5. **Strategic Insights**\n",
        "\n",
        "    Output only the report in a professional, structured format.\n",
        "    Do not repeat the transcript or add explanations.\n",
        "\n",
        "    Transcript:\n",
        "    {{transcript}}\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 3: Inject the actual transcript into the placeholder\n",
        "    user_prompt = user_prompt.replace(\"{{transcript}}\", transcript)\n",
        "\n",
        "    # Step 4: Configure Gemini with the system instruction as a context\n",
        "    config = types.GenerateContentConfig(system_instruction=strategy_system_prompt)\n",
        "\n",
        "    # Step 5: Create a Gemini client with the API key and configuration\n",
        "    sales_client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"), config=config)\n",
        "\n",
        "    # Step 6: Generate the content using the specified Gemini model and composed user prompt\n",
        "    response = sales_client.models.generate_content(\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        contents=user_prompt\n",
        "    )\n",
        "\n",
        "    # Step 7: Return the model's response in a dictionary for further use or formatting\n",
        "    return {\"strategy_report\": response.text}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16ca1db",
      "metadata": {
        "id": "f16ca1db"
      },
      "source": [
        "## üõ†Ô∏è**5. Define Tool Schema**\n",
        "This allows Gemini to call the sales report function as a tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e72b20ff",
      "metadata": {
        "id": "e72b20ff"
      },
      "outputs": [],
      "source": [
        "# üõ†Ô∏è Define the Sales Report Tool Schema\n",
        "# This declares a tool that can be called by the model using structured function-calling syntax\n",
        "\n",
        "sales_report_tool = {\n",
        "    \"name\": \"sales_report\",  # The name of the function/tool the model will call\n",
        "    \"description\": \"Create a sales report for a given transcript\",  # Human-readable purpose\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",  # Parameters passed as a JSON object\n",
        "        \"properties\": {\n",
        "            \"transcript\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Sales transcript\"  # What kind of input is expected\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"transcript\"]  # Enforces that 'transcript' must be provided\n",
        "    }\n",
        "}\n",
        "\n",
        "# üîß Wrap the tool in a Gemini Tool object\n",
        "# This enables the model to call the tool when it's relevant to the user‚Äôs prompt\n",
        "tools = types.Tool(\n",
        "    function_declarations=[sales_report_tool]\n",
        ")\n",
        "\n",
        "# ‚öôÔ∏è Attach the tool configuration to the generation config\n",
        "# This allows Gemini to recognize and use the function in the context of chat generation\n",
        "config = types.GenerateContentConfig(\n",
        "    tools=[tools]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b5f1a40",
      "metadata": {
        "id": "5b5f1a40"
      },
      "source": [
        "## üì§ **6. Provide a Sample Sales Transcript**\n",
        "Gemini will parse this and decide whether to call the appropriate tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b51f23a6",
      "metadata": {
        "id": "b51f23a6"
      },
      "outputs": [],
      "source": [
        "# üìù User Input: Sales Conversation Prompt\n",
        "# This is the initial message coming from the user, simulating a request to analyze a transcript.\n",
        "# The structure uses Gemini's `types.Content` and `types.Part` format to send model-ready input.\n",
        "\n",
        "contents = [\n",
        "    types.Content(\n",
        "        role=\"user\",  # Specifies that this input comes from the user\n",
        "        parts=[\n",
        "            types.Part(\n",
        "                text='''create a sales report for the transcript:\n",
        "\n",
        "                Salesperson: Hi Sarah, thanks for taking the time today. Just to confirm, you're looking to improve your customer onboarding process, right?\n",
        "                Client: Yes, that's right. Our current flow is clunky, and users are dropping off before completing setup.\n",
        "                Salesperson: Got it. Based on what you shared earlier, I think our OnboardPro tool could help streamline that experience. It‚Äôs reduced drop-offs by over 40% for similar clients.\n",
        "                Client: That sounds promising. What would the integration look like?\n",
        "                Salesperson: It‚Äôs a low-code plugin, so your dev team can integrate it in under a week. We also offer support during setup.\n",
        "                Client: Okay, and what's the pricing structure?\n",
        "                Salesperson: It‚Äôs usage-based. For your estimated volume, it would be around $2,000/month.\n",
        "                Client: That might be a stretch for our current budget. Are there tiered options?\n",
        "                Salesperson: Absolutely. We can start with the Lite package at $1,200/month and upgrade later as your usage grows.\n",
        "                Client: That‚Äôs more feasible. Can you send over a detailed proposal?\n",
        "                Salesperson: Of course. I‚Äôll send it today. Would you be open to a follow-up call next Wednesday to walk through it?\n",
        "                Client: Yes, Wednesday works. Thanks!\n",
        "                '''\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "098984e0",
      "metadata": {
        "id": "098984e0"
      },
      "source": [
        "## ü§ñ**7. Execute the Agent and Generate the Strategy Report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ccc6cf54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccc6cf54",
        "outputId": "16df765a-87fd-4626-92a6-1a800a5add81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK. I've created a sales report for the transcript you provided. Here's the strategy report:\n",
            "\n",
            "## Strategy Report\n",
            "\n",
            "**1. Client Needs & Pain Points**\n",
            "\n",
            "*   Inefficient and clunky customer onboarding process.\n",
            "*   High user drop-off rates during the setup phase.\n",
            "*   Budget constraints.\n",
            "\n",
            "**2. Proposed Solutions**\n",
            "\n",
            "*   Implementation of OnboardPro tool to streamline customer onboarding.\n",
            "*   Low-code plugin integration for quick deployment.\n",
            "*   Tiered pricing options (Lite package) to align with budget.\n",
            "\n",
            "**3. Objections or Concerns Raised**\n",
            "\n",
            "*   Initial pricing ($2,000/month) perceived as too high.\n",
            "\n",
            "**4. Next Steps & Follow-ups**\n",
            "\n",
            "*   Send a detailed proposal to the client outlining the OnboardPro solution.\n",
            "*   Schedule a follow-up call for next Wednesday to review the proposal.\n",
            "\n",
            "**5. Strategic Insights**\n",
            "\n",
            "*   Client is budget-conscious, making the Lite package a strategic entry point.\n",
            "*   Highlight the ease of integration (low-code) to address potential technical concerns.\n",
            "*   Quantify the value proposition by emphasizing the reduction in drop-off rates.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# üöÄ Initialize the Gemini Client\n",
        "# This client instance is used to send requests to the Gemini API.\n",
        "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "\n",
        "# üéØ Step 1: Initial Response Generation\n",
        "# Send the user's request and tool definitions to the model.\n",
        "# The model may respond with either direct output or a function call.\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    config=config,\n",
        "    contents=contents\n",
        ")\n",
        "\n",
        "# üß† Step 2: Check if the model made a function call\n",
        "# We access the first candidate's first part to inspect whether a tool was invoked.\n",
        "tool_calls = response.candidates[0].content.parts[0].function_call\n",
        "\n",
        "# ‚úÖ Step 3: If a function call was made, handle it\n",
        "if tool_calls:\n",
        "    if tool_calls.name == \"sales_report\":  # Only handle the \"sales_report\" tool here\n",
        "\n",
        "        # üõ†Ô∏è Execute the corresponding function with the provided transcript\n",
        "        tool_response = sales_report(tool_calls.args['transcript'])\n",
        "\n",
        "        # üîÑ Prepare the tool response part to be passed back to Gemini\n",
        "        function_response_part = types.Part.from_function_response(\n",
        "            name=tool_calls.name,\n",
        "            response={\"result\": tool_response},  # Wrap response in a result object\n",
        "        )\n",
        "\n",
        "        # üß± Step 4: Build the conversation chain\n",
        "        # Add the tool call made by the model\n",
        "        contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=tool_calls)]))\n",
        "\n",
        "        # Add the tool's response to the conversation\n",
        "        contents.append(types.Content(role=\"tool\", parts=[function_response_part]))\n",
        "\n",
        "        # üó£Ô∏è Step 5: Regenerate response with updated conversation history\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            config=config,\n",
        "            contents=contents\n",
        "        )\n",
        "\n",
        "        # üñ®Ô∏è Display final output from the model\n",
        "        print(response.text)\n",
        "\n",
        "else:\n",
        "    # If no tool was called, print the direct model response\n",
        "    print(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_kGyZnBvg_ci"
      },
      "id": "_kGyZnBvg_ci",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}