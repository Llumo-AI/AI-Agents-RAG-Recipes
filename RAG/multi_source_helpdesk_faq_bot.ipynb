{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìò Multi-Retriever RAG Chatbot using PDF, Wikipedia, and Web Search\n",
        "\n",
        "This notebook demonstrates a Retrieval-Augmented Generation (RAG) pipeline that pulls information from multiple sources‚ÄîPDF documents, Wikipedia, and web search‚Äîto answer user queries using OpenAI GPT-4.\n",
        "\n",
        "---\n",
        "\n",
        "üîç **What this notebook does:**\n",
        "\n",
        "- Extracts structured content (text, tables, images) from PDFs using Unstructured.io\n",
        "- Converts extracted content into LangChain documents and embeds them using FAISS\n",
        "- Uses Wikipedia for open-domain factual retrieval\n",
        "- Uses Tavily for live web search (requires API key)\n",
        "- Combines all retrievers into an ensemble using LangChain's `EnsembleRetriever`\n",
        "- Feeds the retrieved context into a GPT-4-powered RAG chain to answer questions\n",
        "\n",
        "---\n",
        "\n",
        "üí° **Example Questions:**\n",
        "\n",
        "- \"Compare Artificial Intelligence and Machine Learning.\"\n",
        "- \"What is the latest trend in Generative AI?\"\n",
        "- \"Summarize the contents of the uploaded PDF.\"\n"
      ],
      "metadata": {
        "id": "FxH-BukcBa5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install dependencies"
      ],
      "metadata": {
        "id": "8DHpo-S4BdoI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhnLdVMCBUfR"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet faiss-cpu pytesseract unstructured-client \"unstructured[all-docs]\"\n",
        "!pip install --quiet langchain_openai langchain-community duckduckgo-search Wikipedia\n",
        "!apt-get -qq install poppler-utils tesseract-ocr libtesseract-dev"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîë Set up API key"
      ],
      "metadata": {
        "id": "isEtZujiBigL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"Enter Your OPENAI_API_KEY\"\n",
        "# os.environ[\"TAVILY_API_KEY\"] = \"Enter Your TAVILY_API_KEY\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY') # Uncomment if you Stored your key securely in Colab\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\") # Uncomment if you Stored your key securely in Colab you can your api key at (https://app.tavily.com/) for free\n",
        "\n"
      ],
      "metadata": {
        "id": "fcjdzRM9Bk_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìÑ Extract Structured Content from PDF  with High-Resolution Layout Parsing\n"
      ],
      "metadata": {
        "id": "saZ7yPdDBmJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured.partition.pdf import partition_pdf\n",
        "\n",
        "filename = \"/content/Ml_sample.pdf\" # Path to your PDF file\n",
        "\n",
        "# Extract elements including images, tables, and structured text\n",
        "pdf_elements = partition_pdf(\n",
        "    filename=filename,\n",
        "    extract_images_in_pdf=True,               # Enable image extraction\n",
        "    strategy=\"hi_res\",                       # Use high-resolution parsing\n",
        "    hi_res_model_name=\"yolox\",               # YOLOX model for detecting layout\n",
        "    infer_table_structure=True,               # Try to parse tables\n",
        "    chunking_strategy=\"by_title\",            # Split text by document headings\n",
        "    max_characters=3000,\n",
        "    combine_text_under_n_chars=200\n",
        ")\n"
      ],
      "metadata": {
        "id": "LVpMuMkWBnte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üîç Inspect parsed elements"
      ],
      "metadata": {
        "id": "-rxIbemVBsc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze the types of elements extracted\n",
        "from collections import Counter\n",
        "category_counts = Counter(str(type(element)) for element in pdf_elements)\n",
        "category_counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3MK0GWBBtHV",
        "outputId": "10f607a6-9daa-4485-dfeb-90c009714d46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({\"<class 'unstructured.documents.elements.CompositeElement'>\": 47})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìö Create LangChain Documents"
      ],
      "metadata": {
        "id": "Ij9FNzzhBvDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert each element into a searchable Document\n",
        "from langchain.schema import Document\n",
        "documents = [Document(page_content=el.text, metadata={\"source\": filename}) for el in pdf_elements]\n"
      ],
      "metadata": {
        "id": "GVxA4uoMB3D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† Embed with OpenAI + FAISS"
      ],
      "metadata": {
        "id": "3I6k0V79B53m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "#Build FAISS Vector Store from the documents\n",
        "embeddings = OpenAIEmbeddings()\n",
        "pdf_vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "#Set up a retriever from the vectorstore\n",
        "pdf_retriever = pdf_vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "MNZIYcTvB6d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÖ Set Up Wikipedia Retriever to Fetch Top 3 Relevant Articles\n",
        "\n"
      ],
      "metadata": {
        "id": "_cUiN5H7B_Da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import WikipediaRetriever\n",
        "\n",
        "def get_wiki_retriever():\n",
        "    # Retrieves top 3 Wikipedia articles\n",
        "    return WikipediaRetriever(top_k_results=3)"
      ],
      "metadata": {
        "id": "BXOg33QXB_x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üåê Create a Web Retriever Using DuckDuckGo Search and an LLM\n"
      ],
      "metadata": {
        "id": "pLBFzFbVCB0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_community.retrievers.tavily_search_api import TavilySearchAPIRetriever\n",
        "\n",
        "def get_web_retriever_tavily():\n",
        "    return TavilySearchAPIRetriever(k=3)"
      ],
      "metadata": {
        "id": "XfpFc5UyCDna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† Combine PDF, Wikipedia, and Web Search into a Unified Retriever"
      ],
      "metadata": {
        "id": "cONb8PnUCGFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "def get_combined_retriever():\n",
        "    return EnsembleRetriever(\n",
        "        retrievers=[\n",
        "            pdf_retriever,\n",
        "            get_wiki_retriever(),\n",
        "            get_web_retriever_tavily()\n",
        "        ],\n",
        "        weights=[1.0, 0.7, 0.7]\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "8iaRWqYcCH9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ü§ñ Create Prompt Template and RAG Chain"
      ],
      "metadata": {
        "id": "Z2xMYg78CL2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a helpful assistant that answers questions based on the provided context, which may include PDFs, Wikipedia, and web search.\n",
        "\n",
        "Question: {input}\n",
        "Context: {context}\n",
        "Answer:\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# ‚úÖ Step 11: Load LLM and Setup RAG Chain\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "combined_retriever = get_combined_retriever()\n",
        "\n",
        "# Setup the complete RAG pipeline\n",
        "rag_chain = (\n",
        "    {\"context\": combined_retriever, \"input\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "yWF7Wg1cCNLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the key takeaways of llumo ai\"\n",
        "response1 = rag_chain.invoke(query)\n",
        "print(response1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmLCCQbiCPyl",
        "outputId": "d8b20688-04a9-4db0-9d1c-1003bdebaabf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some key takeaways of LLUMO AI include delivering exceptional AI solutions, optimizing performance, ensuring technology achieves excellence through innovative and tailored strategies, providing data upload made easy, offering advanced evaluation tools like RAGAs and LLUMO Eval LM for one-click evaluations, customizable KPIs, actionable insights for refining models, and tracking prompt performance on key metrics for production and development.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the output with Llumo Ai\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yNSt8oolCU3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to Evaluate the output\n",
        "User_Query=\"What are the key takeaways of llumo ai\"\n",
        "llm_response=response1\n",
        "inputs = {}\n",
        "import requests\n",
        "# Define the endpoint, headers, and payload\n",
        "LLUMO_ENDPOINT = \"https://app.llumo.ai/api/create-eval-analytics\"\n",
        "headers = {\n",
        "    \"Authorization\": \"Bearer {Your llumo api key}\", # Replace with your LLumo API key it will look like this \"Bearer A1B2C3\"\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "payload = {\n",
        "    \"prompt\": User_Query,\n",
        "    \"input\": inputs,\n",
        "    \"output\": llm_response,\n",
        "    \"analytics\": [\"Context Utilization\"] # ANALYTICS NAME are Confidence,Clarity,Context.....etc.\n",
        "}\n",
        "# Make the API request\n",
        "response = requests.post(LLUMO_ENDPOINT, json=payload, headers=headers)\n",
        "try:\n",
        "    result = response.json()  # Parse the JSON response\n",
        "    print(\"statusCode : \", result['data']['statusCode'])\n",
        "    print(\"message : \",result['data']['message'])\n",
        "    # Extract the 'data' part\n",
        "    data = result.get('data', {})\n",
        "    print(\"Analytics:\", data)\n",
        "    # Return the data and a success flag\n",
        "\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAz37OLnDCaX",
        "outputId": "60358f1d-67f1-4146-8bdd-a6b6e1f34fe5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "statusCode :  200\n",
            "message :  SUCCESS\n",
            "Analytics: {'data': '{\"analyticsScore\": {\"*the output should accurately reflect the core functionalities and benefits of llumo ai.\": 85, \"*the response should be well-structured and easy to understand, using clear and concise language.\": 90, \"*the output must be comprehensive, covering a wide range of llumo ai's features and capabilities.\": 70, \"*the output should be factually accurate and avoid any misleading or false information about llumo ai.\": 95, \"*the response should be relevant to the prompt and directly address the user's request for key takeaways.\": 100, \"overallScore\": 88}, \"reasoning\": {\"*the output should accurately reflect the core functionalities and benefits of llumo ai.\": [\"The output correctly identifies several key functionalities of LLUMO AI, such as delivering AI solutions, performance optimization, and providing evaluation tools.\", \"It also mentions important benefits like easy data upload, customizable KPIs, and actionable insights.\", \"The description is concise and avoids unnecessary jargon.\", \"However, it could benefit from quantifiable examples or case studies to further strengthen its claims.  A brief mention of the target audience would also improve the response.\"], \"*the response should be well-structured and easy to understand, using clear and concise language.\": [\"The output is well-organized, presenting the key takeaways in a clear and logical manner.\", \"The language used is professional and easy to understand, avoiding technical jargon where possible.\", \"The points are presented in a way that is easy to follow and digest.\", \"The conciseness makes it highly readable and impactful.\"], \"*the output must be comprehensive, covering a wide range of llumo ai's features and capabilities.\": [\"The output covers several important aspects of LLUMO AI, but it might not be entirely comprehensive.\", \"While it mentions key features like evaluation tools and data upload, it could benefit from including other potential features or capabilities to provide a more holistic view.\", \"The response touches upon the core functionalities but lacks depth in certain areas.  More detail on specific applications or use cases would improve comprehensiveness.\"], \"*the output should be factually accurate and avoid any misleading or false information about llumo ai.\": [\"Based on the information provided, the output appears to be factually accurate in its description of LLUMO AI's features and capabilities.\", \"There is no evidence of misleading or false information.\", \"The claims made are plausible and consistent with what one might expect from an AI solution provider.\"], \"*the response should be relevant to the prompt and directly address the user's request for key takeaways.\": [\"The output directly answers the prompt by providing a list of key takeaways from LLUMO AI.\", \"All the points mentioned are relevant to the core functionalities and benefits of the AI system.\", \"There is no irrelevant information or digression from the main topic.\"], \"overallScore\": \"Calculated based on individual metric scores\"}, \"inputTokenCount\": 10, \"outputTokenCount\": 76, \"totalToken\": 86, \"cost\": 0.0005160000000000001, \"isRepeat\": false, \"isError\": true, \"isRefusal\": true}', 'statusCode': 200, 'message': 'SUCCESS'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HeCcsYJXDQUj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}