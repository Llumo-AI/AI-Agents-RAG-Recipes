# AI-Agents-RAG-Recipes

Practical AI recipes for building intelligent agentic workflows and optimizing RAG-based LLM applications.

Hey there! Welcome to this collection of advanced and agentic Retrieval-Augmented Generation (RAG) techniques. If you're working with Large Language Models (LLMs) and want to enhance their accuracy and relevance, you're in the right place!

### ğŸŒŸ Why RAG?

LLMs are great, but they have limitationsâ€”they rely on static training data and can sometimes make things up (a.k.a. "hallucinations"). Instead of constantly retraining models, RAG allows us to dynamically retrieve relevant, up-to-date information from external sources. That means smarter, more reliable AI responses!

This repo simplifies the process by offering ready-to-use implementations and guidance on evaluating their performance.

---

## ğŸ” How Does RAG Work?

Think of RAG as a four-step process:

1ï¸âƒ£ **Indexing** â€“ Breaks down documents into chunks and stores them in an efficient way (usually as embeddings in a vector database).
2ï¸âƒ£ **Retrieving** â€“ Finds the most relevant documents based on a userâ€™s query.
3ï¸âƒ£ **Augmenting** â€“ Adds this retrieved information to the query, giving the LLM extra context.
4ï¸âƒ£ **Generating** â€“ Produces a final, well-informed response.

With this setup, your AI system isnâ€™t just guessingâ€”itâ€™s actually using external knowledge to generate answers.

---

## ğŸ“Š Why Evaluation Matters

Not all RAG implementations are equal! Evaluating RAG applications ensures that the retrieval and generation work together smoothly. Proper evaluation helps refine your model, making sure it delivers useful and trustworthy results in real-world applications like chatbots, summarization tools, and question-answering systems.

---

## âš™ï¸ Advanced RAG Techniques

This repo covers a variety of ways to make RAG even better. Some techniques focus on **improving search accuracy** (like hybrid approaches), while others help with **structuring retrieved information** before passing it to an LLM. The goal? Less fluff, more relevant answers!

Some advanced techniques youâ€™ll find here include:

- **Hybrid RAG** â€“ Combines different search strategies for better results.
- **HyDE (Hypothetical Document Embeddings)** â€“ Generates example responses to improve retrieval.
- **Contextual RAG** â€“ Filters unnecessary details to keep responses concise.
- **RAG Fusion** â€“ Ranks and merges multiple retrieval results for better accuracy.

And much more!

---

## ğŸ¤– Agentic RAG: Taking It a Step Further

Agentic RAG introduces **AI agents** that can interact with different tools, refine retrieved results, or even search the web dynamically. These techniques help make AI systems more flexible and adaptive.

Some key agentic techniques include:

- **Self-RAG** â€“ Ensures responses are complete and accurate by double-checking retrieved data.
- **Corrective RAG** â€“ Filters out irrelevant information and refines search queries.
- **Adaptive RAG** â€“ Adjusts retrieval strategies based on the type of query.
- **ReAct RAG** â€“ Combines reasoning and retrieval to improve contextual understanding.

With these techniques, AI systems donâ€™t just passively retrieve informationâ€”they actively refine their responses.

---

## ğŸ› ï¸ Getting Started

To get started, simply clone this repo:

```bash
git clone https://github.com/Llumo-AI/AI-Agents-RAG-Recipes.git
cd AI-Agents-RAG-Recipes
```
